{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv( \"../data/processed/train_1.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test_1.csv\")\n",
    "validation = pd.read_csv(\"../data/processed/validation_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train['review']\n",
    "y = train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tfidf..\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating tfidf..\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the \"TfidfVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "tvec = TfidfVectorizer(analyzer = \"word\",\n",
    "                            stop_words=None,\n",
    "                            max_features=100000,\n",
    "                            ngram_range=(1, 3)) \n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "lr = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def lr_cv(splits, X, Y, pipeline, average_method):\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=777)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        lr_fit = pipeline.fit(X[train], Y[train])\n",
    "        prediction = lr_fit.predict(X[test])\n",
    "        scores = lr_fit.score(X[test],Y[test])\n",
    "        \n",
    "        accuracy.append(scores * 100)\n",
    "        precision.append(precision_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('              negative    positive')\n",
    "        print('precision:',precision_score(Y[test], prediction, average=None))\n",
    "        recall.append(recall_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('recall:   ',recall_score(Y[test], prediction, average=None))\n",
    "        f1.append(f1_score(Y[test], prediction, average=average_method)*100)\n",
    "        print('f1 score: ',f1_score(Y[test], prediction, average=None))\n",
    "        print('-'*50)\n",
    "\n",
    "    print(\"accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print(\"precision: %.2f%% (+/- %.2f%%)\" % (np.mean(precision), np.std(precision)))\n",
    "    print(\"recall: %.2f%% (+/- %.2f%%)\" % (np.mean(recall), np.std(recall)))\n",
    "    print(\"f1 score: %.2f%% (+/- %.2f%%)\" % (np.mean(f1), np.std(f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    positive\n",
      "precision: [0.72706682 0.80921339]\n",
      "recall:    [0.59389454 0.88540181]\n",
      "f1 score:  [0.65376782 0.84559491]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.71490281 0.81443756]\n",
      "recall:    [0.61239593 0.87446505]\n",
      "f1 score:  [0.65969108 0.84338454]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.6987041  0.80779451]\n",
      "recall:    [0.59851989 0.86733238]\n",
      "f1 score:  [0.6447434  0.83650539]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.70964247 0.8119469 ]\n",
      "recall:    [0.60648148 0.87256301]\n",
      "f1 score:  [0.65401897 0.84116434]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.70819672 0.80952381]\n",
      "recall:    [0.6        0.87303852]\n",
      "f1 score:  [0.64962406 0.84008236]\n",
      "--------------------------------------------------\n",
      "accuracy: 78.21% (+/- 0.37%)\n",
      "precision: 76.11% (+/- 0.51%)\n",
      "recall: 73.84% (+/- 0.35%)\n",
      "f1 score: 74.69% (+/- 0.38%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "original_pipeline = Pipeline([\n",
    "    ('vectorizer', tvec),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "lr_cv(5,X,y,original_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),lr)\n",
    "SMOTE_pipeline = make_pipeline(tvec, SMOTE(random_state=777),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    positive\n",
      "precision: [0.65613718 0.82947977]\n",
      "recall:    [0.67252544 0.81883024]\n",
      "f1 score:  [0.66423024 0.8241206 ]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.63301141 0.82396088]\n",
      "recall:    [0.66697502 0.80123633]\n",
      "f1 score:  [0.64954955 0.81243973]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.63101604 0.81910766]\n",
      "recall:    [0.65494912 0.80313837]\n",
      "f1 score:  [0.64275987 0.81104442]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.64674398 0.82783705]\n",
      "recall:    [0.6712963  0.81169757]\n",
      "f1 score:  [0.65879146 0.81968788]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.6362054  0.82841691]\n",
      "recall:    [0.67685185 0.80123633]\n",
      "f1 score:  [0.65589951 0.81459995]\n",
      "--------------------------------------------------\n",
      "accuracy: 76.01% (+/- 0.59%)\n",
      "precision: 73.32% (+/- 0.63%)\n",
      "recall: 73.79% (+/- 0.58%)\n",
      "f1 score: 73.53% (+/- 0.61%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5,X,y, ROS_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    positive\n",
      "precision: [0.63734115 0.8014808 ]\n",
      "recall:    [0.60314524 0.82358535]\n",
      "f1 score:  [0.61977186 0.81238274]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.61660777 0.81335283]\n",
      "recall:    [0.64569843 0.79362815]\n",
      "f1 score:  [0.63081789 0.80336943]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.61939616 0.80679101]\n",
      "recall:    [0.62627197 0.80218735]\n",
      "f1 score:  [0.62281509 0.80448259]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.62923351 0.81853469]\n",
      "recall:    [0.6537037  0.80218735]\n",
      "f1 score:  [0.64123524 0.81027858]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.62769784 0.81554804]\n",
      "recall:    [0.6462963  0.80313837]\n",
      "f1 score:  [0.63686131 0.80929564]\n",
      "--------------------------------------------------\n",
      "accuracy: 74.73% (+/- 0.37%)\n",
      "precision: 71.86% (+/- 0.40%)\n",
      "recall: 72.00% (+/- 0.57%)\n",
      "f1 score: 71.91% (+/- 0.45%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, X,y, SMOTE_pipeline, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "RUS_pipeline = make_pipeline(tvec, RandomUnderSampler(random_state=777),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              negative    positive\n",
      "precision: [0.62092494 0.85951743]\n",
      "recall:    [0.75763182 0.76224441]\n",
      "f1 score:  [0.6825     0.80796371]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.60353721 0.85659551]\n",
      "recall:    [0.75763182 0.74417499]\n",
      "f1 score:  [0.67186218 0.79643766]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.59622367 0.85611511]\n",
      "recall:    [0.75948196 0.73561579]\n",
      "f1 score:  [0.66802278 0.79130435]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.58857143 0.85642176]\n",
      "recall:    [0.76296296 0.72610556]\n",
      "f1 score:  [0.66451613 0.7858981 ]\n",
      "--------------------------------------------------\n",
      "              negative    positive\n",
      "precision: [0.59037037 0.84560829]\n",
      "recall:    [0.73796296 0.73704232]\n",
      "f1 score:  [0.65596708 0.78760163]\n",
      "--------------------------------------------------\n",
      "accuracy: 74.58% (+/- 0.85%)\n",
      "precision: 72.74% (+/- 0.76%)\n",
      "recall: 74.81% (+/- 0.74%)\n",
      "f1 score: 73.12% (+/- 0.82%)\n"
     ]
    }
   ],
   "source": [
    "lr_cv(5, X, y, RUS_pipeline, 'macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
