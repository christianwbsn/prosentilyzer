{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv( \"../data/interim/lazada_review_stemmed_v2.0_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['review'] = raw['review'].apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kirim',\n",
       " 'lalu',\n",
       " 'ninja',\n",
       " 'sangat',\n",
       " 'lama',\n",
       " 'jauh',\n",
       " 'beda',\n",
       " 'dengan',\n",
       " 'kurir',\n",
       " 'internal',\n",
       " 'lazada',\n",
       " 'lebih',\n",
       " 'baik',\n",
       " 'kasih',\n",
       " 'opsi',\n",
       " 'langgan',\n",
       " 'agar',\n",
       " 'bisa',\n",
       " 'pilih',\n",
       " 'kurir']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 08:32:49,183 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "sentences = raw['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-11 08:32:49,198 : INFO : collecting all words and their counts\n",
      "2018-07-11 08:32:49,203 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-07-11 08:32:49,228 : INFO : PROGRESS: at sentence #10000, processed 95241 words, keeping 2799 word types\n",
      "2018-07-11 08:32:49,255 : INFO : collected 4668 word types from a corpus of 228695 raw words and 19898 sentences\n",
      "2018-07-11 08:32:49,256 : INFO : Loading a fresh vocabulary\n",
      "2018-07-11 08:32:49,261 : INFO : min_count=40 retains 527 unique words (11% of original 4668, drops 4141)\n",
      "2018-07-11 08:32:49,262 : INFO : min_count=40 leaves 209230 word corpus (91% of original 228695, drops 19465)\n",
      "2018-07-11 08:32:49,270 : INFO : deleting the raw counts dictionary of 4668 items\n",
      "2018-07-11 08:32:49,273 : INFO : sample=0.001 downsamples 78 most-common words\n",
      "2018-07-11 08:32:49,274 : INFO : downsampling leaves estimated 128216 word corpus (61.3% of prior 209230)\n",
      "2018-07-11 08:32:49,276 : INFO : estimated required memory for 527 words and 300 dimensions: 1528300 bytes\n",
      "2018-07-11 08:32:49,277 : INFO : resetting layer weights\n",
      "2018-07-11 08:32:49,294 : INFO : training model with 4 workers on 527 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-07-11 08:32:49,459 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-11 08:32:49,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-11 08:32:49,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-11 08:32:49,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-11 08:32:49,478 : INFO : EPOCH - 1 : training on 228695 raw words (128151 effective words) took 0.2s, 728085 effective words/s\n",
      "2018-07-11 08:32:49,649 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-11 08:32:49,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-11 08:32:49,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-11 08:32:49,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-11 08:32:49,673 : INFO : EPOCH - 2 : training on 228695 raw words (127991 effective words) took 0.2s, 685862 effective words/s\n",
      "2018-07-11 08:32:49,845 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-11 08:32:49,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-11 08:32:49,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-11 08:32:49,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-11 08:32:49,866 : INFO : EPOCH - 3 : training on 228695 raw words (128387 effective words) took 0.2s, 707900 effective words/s\n",
      "2018-07-11 08:32:50,039 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-11 08:32:50,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-11 08:32:50,051 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-11 08:32:50,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-11 08:32:50,058 : INFO : EPOCH - 4 : training on 228695 raw words (128040 effective words) took 0.2s, 706302 effective words/s\n",
      "2018-07-11 08:32:50,239 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-11 08:32:50,240 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-11 08:32:50,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-11 08:32:50,249 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-11 08:32:50,250 : INFO : EPOCH - 5 : training on 228695 raw words (127913 effective words) took 0.2s, 702113 effective words/s\n",
      "2018-07-11 08:32:50,251 : INFO : training on a 1143475 raw words (640482 effective words) took 1.0s, 669517 effective words/s\n",
      "2018-07-11 08:32:50,253 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-07-11 08:32:50,260 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2018-07-11 08:32:50,261 : INFO : not storing attribute vectors_norm\n",
      "2018-07-11 08:32:50,264 : INFO : not storing attribute cum_table\n",
      "2018-07-11 08:32:50,279 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "            size=num_features, min_count = min_word_count,\n",
    "            window = context, sample = downsampling)\n",
    "model.init_sims(replace=True)\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lex', 0.933557391166687),\n",
       " ('ninja', 0.8309380412101746),\n",
       " ('rumah', 0.8126482963562012),\n",
       " ('antar', 0.8105541467666626),\n",
       " ('express', 0.7822293639183044),\n",
       " ('ramah', 0.7594882845878601),\n",
       " ('one', 0.6775049567222595),\n",
       " ('layan', 0.6756379008293152),\n",
       " ('tempat', 0.6627054810523987),\n",
       " ('proses', 0.6541668176651001)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kurir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jiwa', 0.8912090063095093),\n",
       " ('pokok', 0.8723122477531433),\n",
       " ('rekomendasi', 0.8274660706520081),\n",
       " ('oke', 0.8247707486152649),\n",
       " ('keren', 0.8217877149581909),\n",
       " ('muas', 0.7952912449836731),\n",
       " ('gin', 0.7788281440734863),\n",
       " ('riah', 0.7736654281616211),\n",
       " ('elegan', 0.7718223929405212),\n",
       " ('ekspektasi', 0.754769504070282)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"mantap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gawai', 0.7034754753112793),\n",
       " ('lazada', 0.690081000328064),\n",
       " ('darat', 0.6896671652793884),\n",
       " ('selamat', 0.6381320357322693),\n",
       " ('selera', 0.6152774095535278),\n",
       " ('kerja', 0.6084685325622559),\n",
       " ('tuju', 0.5951776504516602),\n",
       " ('kamu', 0.5823189616203308),\n",
       " ('alhamdulilah', 0.503341555595398),\n",
       " ('jadwal', 0.49905356764793396)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"terima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gawai', 0.6531863212585449),\n",
       " ('selera', 0.6213202476501465),\n",
       " ('lazada', 0.5957981944084167),\n",
       " ('sukses', 0.575785219669342),\n",
       " ('kamu', 0.5577393174171448),\n",
       " ('darat', 0.5537471175193787),\n",
       " ('cinta', 0.5337961316108704),\n",
       " ('dan', 0.530433177947998),\n",
       " ('maju', 0.5183781385421753),\n",
       " ('alhamdulilah', 0.5167912840843201)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kasih\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cewek', 0.9715321660041809),\n",
       " ('kaca', 0.9433884620666504),\n",
       " ('kaya', 0.9425203800201416),\n",
       " ('yah', 0.9410569667816162),\n",
       " ('jarum', 0.9304667711257935),\n",
       " ('putus', 0.9303438067436218),\n",
       " ('main', 0.9299447536468506),\n",
       " ('cowok', 0.9272971153259277),\n",
       " ('tali', 0.927254319190979),\n",
       " ('sedih', 0.9260545969009399)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"jelek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pernah', 0.8638545870780945),\n",
       " ('jual', 0.8139086961746216),\n",
       " ('customer', 0.8089202046394348),\n",
       " ('mau', 0.7955259084701538),\n",
       " ('langgan', 0.7924652099609375),\n",
       " ('tolong', 0.7831017374992371),\n",
       " ('dong', 0.7827646136283875),\n",
       " ('jangan', 0.781039834022522),\n",
       " ('minta', 0.7753928303718567),\n",
       " ('pasti', 0.770636260509491)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"kecewa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "tvec_weights = vectorizer.fit_transform(raw['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>barang</td>\n",
       "      <td>0.067850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>bagus</td>\n",
       "      <td>0.059888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>terima</td>\n",
       "      <td>0.054614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>cepat</td>\n",
       "      <td>0.052042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>kasih</td>\n",
       "      <td>0.048056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>kirim</td>\n",
       "      <td>0.045308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>lazada</td>\n",
       "      <td>0.045139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>mantap</td>\n",
       "      <td>0.043854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>sampai</td>\n",
       "      <td>0.042312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>sesuai</td>\n",
       "      <td>0.039849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>dan</td>\n",
       "      <td>0.037596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>tidak</td>\n",
       "      <td>0.034552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>oke</td>\n",
       "      <td>0.033636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>sudah</td>\n",
       "      <td>0.032778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>dengan</td>\n",
       "      <td>0.030443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>harga</td>\n",
       "      <td>0.026694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>sekali</td>\n",
       "      <td>0.026369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>yang</td>\n",
       "      <td>0.026087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>pesan</td>\n",
       "      <td>0.024575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>saya</td>\n",
       "      <td>0.024124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>baik</td>\n",
       "      <td>0.022576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>murah</td>\n",
       "      <td>0.020407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>tapi</td>\n",
       "      <td>0.020386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>jelas</td>\n",
       "      <td>0.019698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>produk</td>\n",
       "      <td>0.018271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>jam</td>\n",
       "      <td>0.018131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>rapi</td>\n",
       "      <td>0.017098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>sangat</td>\n",
       "      <td>0.016521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>juga</td>\n",
       "      <td>0.016161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>telah</td>\n",
       "      <td>0.004698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>aku</td>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>layan</td>\n",
       "      <td>0.004627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>rusak</td>\n",
       "      <td>0.004573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>cukup</td>\n",
       "      <td>0.004518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>selalu</td>\n",
       "      <td>0.004442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>langsung</td>\n",
       "      <td>0.004391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>atau</td>\n",
       "      <td>0.004322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>harap</td>\n",
       "      <td>0.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>belanja</td>\n",
       "      <td>0.004260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>memang</td>\n",
       "      <td>0.004238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>paket</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>biasa</td>\n",
       "      <td>0.004189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>mati</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>sukses</td>\n",
       "      <td>0.004102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>tempered</td>\n",
       "      <td>0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>lambat</td>\n",
       "      <td>0.004010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>cacat</td>\n",
       "      <td>0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>minggu</td>\n",
       "      <td>0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>mesan</td>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>dua</td>\n",
       "      <td>0.003947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>tanggal</td>\n",
       "      <td>0.003939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>tolong</td>\n",
       "      <td>0.003878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>kenapa</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>padahal</td>\n",
       "      <td>0.003856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>bagaimana</td>\n",
       "      <td>0.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>itu</td>\n",
       "      <td>0.003742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>kamu</td>\n",
       "      <td>0.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>sekarang</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>glass</td>\n",
       "      <td>0.003689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           term    weight\n",
       "312      barang  0.067850\n",
       "241       bagus  0.059888\n",
       "4288     terima  0.054614\n",
       "672       cepat  0.052042\n",
       "1904      kasih  0.048056\n",
       "2047      kirim  0.045308\n",
       "2261     lazada  0.045139\n",
       "2480     mantap  0.043854\n",
       "3657     sampai  0.042312\n",
       "3877     sesuai  0.039849\n",
       "800         dan  0.037596\n",
       "4335      tidak  0.034552\n",
       "2941        oke  0.033636\n",
       "4080      sudah  0.032778\n",
       "856      dengan  0.030443\n",
       "1497      harga  0.026694\n",
       "3760     sekali  0.026369\n",
       "4651       yang  0.026087\n",
       "3206      pesan  0.024575\n",
       "3710       saya  0.024124\n",
       "254        baik  0.022576\n",
       "2729      murah  0.020407\n",
       "4207       tapi  0.020386\n",
       "1765      jelas  0.019698\n",
       "3331     produk  0.018271\n",
       "1726        jam  0.018131\n",
       "10          ada  0.017800\n",
       "3431       rapi  0.017098\n",
       "3671     sangat  0.016521\n",
       "1806       juga  0.016161\n",
       "...         ...       ...\n",
       "4238      telah  0.004698\n",
       "69          aku  0.004667\n",
       "2256      layan  0.004627\n",
       "3612      rusak  0.004573\n",
       "772       cukup  0.004518\n",
       "3774     selalu  0.004442\n",
       "2229   langsung  0.004391\n",
       "203        atau  0.004322\n",
       "1491      harap  0.004283\n",
       "385     belanja  0.004260\n",
       "2555     memang  0.004238\n",
       "3042      paket  0.004225\n",
       "462       biasa  0.004189\n",
       "2522       mati  0.004149\n",
       "4094     sukses  0.004102\n",
       "4260   tempered  0.004033\n",
       "2215     lambat  0.004010\n",
       "617       cacat  0.004005\n",
       "2635     minggu  0.003983\n",
       "2600      mesan  0.003965\n",
       "1049        dua  0.003947\n",
       "4193    tanggal  0.003939\n",
       "4387     tolong  0.003878\n",
       "1968     kenapa  0.003858\n",
       "3025    padahal  0.003856\n",
       "236   bagaimana  0.003842\n",
       "1698        itu  0.003742\n",
       "1871       kamu  0.003722\n",
       "3763   sekarang  0.003718\n",
       "1399      glass  0.003689\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
