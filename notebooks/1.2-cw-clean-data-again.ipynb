{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv( \"../data/interim/lazada_review_clean_v2.0_2.csv\")\n",
    "slang_words = pd.read_csv(\"../data/external/kbba_ID.txt\",\n",
    "                        sep=\"\\t\", header=None)\n",
    "slang = pd.read_csv(\"../data/external/slangword_ID.txt\",\n",
    "                        sep=\":\", header=None)\n",
    "baku_words = pd.read_csv(\"../data/external/katabaku_ID.txt\",\n",
    "                        sep=\"|\", header=None)\n",
    "baku_words.columns = [1,0]\n",
    "root_words = np.array(pd.read_csv(\"../data/external/rootword_ID.txt\",\n",
    "                        sep=\"\\n\", header=None).values)\n",
    "slang_words = pd.concat([slang_words, slang, baku_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_words.drop_duplicates(inplace=True)\n",
    "slang_words = dict(zip(slang_words[0],slang_words[1]))\n",
    "raw['review'] = raw['review'].apply(lambda x: x.replace(\",\",\" \"))\n",
    "def delete_suffix_nya(review):\n",
    "    return re.sub(\"(?:nya|ny|y)[$|\\s]\",\" \",review)\n",
    "    \n",
    "raw['review'] = raw['review'].apply(delete_suffix_nya)\n",
    "raw['review'] = raw['review'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_slang_words(review):\n",
    "    return [slang_words[word] if word in slang_words else word for word in review]\n",
    "raw['review'] = raw['review'].apply(mapping_slang_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_string(word_list):\n",
    "    return \",\".join(word_list)\n",
    "raw['review'] = raw['review'].apply(convert_list_to_string)\n",
    "raw = raw.dropna(subset=['review'],how='all')\n",
    "raw = raw[raw['review'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(words):\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "raw['avg_word'] = raw['review'].apply(lambda x: avg_word(x.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv(\"../data/interim/lazada_review_clean_v2.0_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spellCheck:\n",
    "    def train(self,features):\n",
    "        model = collections.defaultdict(lambda:1)\n",
    "        for f in features:\n",
    "            model[f] += 1\n",
    "        return model\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.NWORDS = self.train(self.words(open('../data/external/spellingset_ID.txt').read()))\n",
    "        self.alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    def words(self,text):\n",
    "        return re.findall('[a-z]+', text.lower())\n",
    "    \n",
    "    def edits1(self, word):\n",
    "        splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes    = [a + b[1:] for a, b in splits if b]\n",
    "        transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "        replaces   = [a + c + b[1:] for a, b in splits for c in self.alphabet if b]\n",
    "        inserts    = [a + c + b     for a, b in splits for c in self.alphabet]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "    \n",
    "    def known_edits2(self, word):\n",
    "        return set(e2 for e1 in self.edits1(word) for e2 in self.edits1(e1) if e2 in self.NWORDS)\n",
    "\n",
    "    def known(self,words): return set(w for w in words if w in self.NWORDS)\n",
    "\n",
    "    def correct(self, word):\n",
    "        candidates = self.known([word]) or self.known(self.edits1(word)) or self.known_edits2(word) or [word]\n",
    "        return max(candidates, key=self.NWORDS.get)\n",
    "\n",
    "def correctSpelling(text):\n",
    "    sc = spellCheck()\n",
    "    return sc.correct(text) if text not in root_words else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(word_list):\n",
    "    transformed = []\n",
    "    for word in word_list:\n",
    "        transformed.append(correctSpelling(word))\n",
    "    return np.array(transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
