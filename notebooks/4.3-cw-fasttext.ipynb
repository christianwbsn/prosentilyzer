{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv( \"../data/processed/train_1.csv\")\n",
    "test = pd.read_csv(\"../data/processed/test_1.csv\")\n",
    "validation = pd.read_csv(\"../data/processed/validation_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train['review']\n",
    "y = train['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 300686\n",
      "Dimension of a word vector: 300\n",
      "Vector components of a word: [-0.020878  -0.098768   0.010647   0.029345  -0.066832   0.20484\n",
      " -0.12876   -0.041663   0.15152    0.10408   -0.25066    0.18666\n",
      " -0.037608  -0.31225   -0.1883    -0.13681   -0.17851   -0.20356\n",
      " -0.28021   -0.01756    0.07171    0.11328   -0.22029   -0.083482\n",
      " -0.19687    0.056111  -0.11775    0.062158  -0.085196   0.20082\n",
      "  0.57581   -0.083127   0.018557  -0.12359   -0.38605   -0.30369\n",
      "  0.042381  -0.086606   0.021943   0.031174   0.18783    0.27425\n",
      " -0.16156    0.42373    0.24293    0.19421    0.56379   -0.042846\n",
      "  0.0037499 -0.035674   0.11309    0.22571   -0.37663   -0.051349\n",
      " -0.062389  -0.048832   0.26946    0.19802   -0.3773     0.0048868\n",
      "  0.17017   -0.042761   0.13404    0.15675   -0.12758   -0.22971\n",
      " -0.1304     0.33002    0.18366   -0.0072019 -0.15981   -0.41593\n",
      " -0.054073   0.0021753 -0.066927   0.16821   -0.1285    -0.19194\n",
      " -0.28232   -0.30573    0.26306   -0.099999   0.14894    0.22159\n",
      " -0.057842  -0.10012    0.32231   -0.00759    0.082615   0.19798\n",
      "  0.1389    -0.30912    0.0021005  0.2342    -0.21598    0.043296\n",
      "  0.076964  -0.16209   -0.091678   0.0028674 -0.030564   0.14988\n",
      " -0.04276    0.027413   0.097786  -0.1108    -0.075119  -0.26374\n",
      " -0.2874     0.14084    0.17326   -0.24946    0.18887   -0.29644\n",
      "  0.37031    0.060894   0.64862    0.11679   -0.072919  -0.086513\n",
      "  0.013335   0.073289   0.16469    0.033692   0.43979   -0.022368\n",
      " -0.15887   -0.03671    0.1983     0.033867  -0.04212    0.14395\n",
      "  0.53586   -0.50411   -0.13124   -0.29385   -0.14305    0.119\n",
      " -0.050331   0.25418   -0.033426   0.21912    0.24887    0.12063\n",
      " -0.096552  -0.40477   -0.098667   0.012784  -0.23409   -0.26871\n",
      " -0.25185    0.28119    0.40018   -0.069994   0.16453   -0.10654\n",
      "  0.1491     0.15295   -0.16653    0.32313   -0.13107    0.29038\n",
      " -0.10916   -0.070509   0.17909   -0.078218  -0.071862  -0.20665\n",
      " -0.042241   0.25344    0.14904    0.21619   -0.3269     0.048437\n",
      "  0.04079    0.16568   -0.22664   -0.15149   -0.11488   -0.10366\n",
      " -0.1909     0.1482     0.086469   0.11797   -0.069632  -0.093287\n",
      " -0.040855   0.10033    0.045621  -0.0147    -0.015647  -0.29505\n",
      " -0.021292   0.16535    0.069329  -0.011685   0.057418   0.29638\n",
      " -0.14603    0.024911  -0.14179    0.11311   -0.12294   -0.28517\n",
      "  0.18393    0.017878  -0.01174   -0.11885   -0.12327   -0.13278\n",
      "  0.19518    0.063991  -0.31825    0.0064196 -0.24455    0.047465\n",
      "  0.056698   0.14097    0.13103    0.060431   0.001404   0.53137\n",
      "  0.22407   -0.36189    0.26555    0.12652    0.15998    0.014373\n",
      "  0.067048   0.014418  -0.11098    0.18909   -0.12791   -0.021157\n",
      "  0.40865   -0.27431    0.026093  -0.028435  -0.10846    0.21894\n",
      " -0.28586    0.26357   -0.079023  -0.36187    0.027073   0.040904\n",
      " -0.011724  -0.12126    0.051447   0.032512   0.1476    -0.16985\n",
      "  0.35057   -0.025756   0.31885   -0.17143   -0.60601   -0.056649\n",
      "  0.081557   0.12466    0.15893   -0.12835    0.42525   -0.054239\n",
      " -0.055752   0.058622   0.19201   -0.12804    0.013381  -0.33754\n",
      " -0.0057527 -0.063113   0.35394   -0.49798    0.13845    0.58718\n",
      "  0.31443   -0.21815   -0.15569   -0.024661   0.083794   0.011737\n",
      " -0.15916   -0.12333    0.34765    0.17257    0.22034   -0.13023\n",
      " -0.27012    0.1288    -0.14332   -0.1633    -0.26255    0.26322\n",
      " -0.13401   -0.20823   -0.096737   0.26358   -0.18249   -0.37564  ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "id_model = KeyedVectors.load_word2vec_format('../data/external/wiki.id.vec')\n",
    "words = []\n",
    "for word in id_model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))\n",
    "\n",
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(id_model[words[0]])\n",
    "))\n",
    "\n",
    "# Print out the vector of a word \n",
    "print(\"Vector components of a word: {}\".format(\n",
    "    id_model[words[0]]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.array([])\n",
    "limit = 500\n",
    "vector_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 0 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f98a83a4b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Finally plotting and saving the fig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mplot_with_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow_dim_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-2f98a83a4b87>\u001b[0m in \u001b[0;36mplot_with_labels\u001b[0;34m(low_dim_embs, labels, filename)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# in inches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow_dim_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         plt.annotate(label,\n",
      "\u001b[0;31mIndexError\u001b[0m: index 500 is out of bounds for axis 0 with size 500"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "for word in id_model.vocab:\n",
    "    # Break the loop if limit exceeds \n",
    "    if i == limit: break\n",
    "\n",
    "    # Getting token \n",
    "    words.append(word)\n",
    "\n",
    "    # Appending the vectors \n",
    "    embedding = np.append(embedding, id_model[word])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Reshaping the embedding vector \n",
    "embedding = embedding.reshape(limit, vector_dim)\n",
    "\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "#     assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "# Creating the tsne plot [Warning: will take time]\n",
    "tsne = TSNE(perplexity=30.0, n_components=2, init='pca', n_iter=5000)\n",
    "\n",
    "low_dim_embedding = tsne.fit_transform(embedding)\n",
    "\n",
    "# Finally plotting and saving the fig \n",
    "plot_with_labels(low_dim_embedding, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "CPU times: user 1min 1s, sys: 133 ms, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "%time forest = forest.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features = vectorizer.transform(X_test)\n",
    "test_data_features = test_data_features.toarray()\n",
    "pred = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7710427135678392\n",
      "Confusion Matrix: [[ 579  497]\n",
      " [ 232 1876]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss,confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "acc = accuracy_score(y_test,pred)\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "print(\"Accuracy Score: \" + str(acc))\n",
    "print(\"Confusion Matrix: \"+ str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 3.97 ms, total: 149 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "%time nb.fit(train_data_features, y_train)\n",
    "pred = nb.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7584798994974874\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy Score: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 0.6620603015075377\n"
     ]
    }
   ],
   "source": [
    "null_ = []\n",
    "for i in range(0,len(y_test)):\n",
    "    null_.append(1)\n",
    "null_accuracy = accuracy_score(y_test, null_)\n",
    "print('Null accuracy:', null_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.88 s, sys: 27.8 ms, total: 5.91 s\n",
      "Wall time: 1.6 s\n",
      "Accuracy Score: 0.7751256281407035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "lgbm = lgb.LGBMClassifier()\n",
    "%time lgbm.fit(train_data_features, y_train)\n",
    "pred = lgbm.predict(test_data_features)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy Score: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 296 ms, total: 1min 29s\n",
      "Wall time: 1min 29s\n",
      "Accuracy Score: 0.7550251256281407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakama/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgbo = xgb.XGBClassifier()\n",
    "%time xgbo.fit(train_data_features, y_train)\n",
    "predic = xgbo.predict(test_data_features)\n",
    "acc = accuracy_score(y_test, predic)\n",
    "print(\"Accuracy Score: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 157 ms, sys: 5 Âµs, total: 157 ms\n",
      "Wall time: 157 ms\n",
      "Accuracy Score: 0.7713567839195979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "%time logistic.fit(train_data_features, y_train)\n",
    "predic = logistic.predict(test_data_features)\n",
    "acc = accuracy_score(y_test, predic)\n",
    "print(\"Accuracy Score: \" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
